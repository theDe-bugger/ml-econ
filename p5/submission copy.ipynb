{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Data\n",
    "data = pd.read_csv(\"./Econ424_F2023_PC4_training_data_small.csv\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find in missing values\n",
    "missing = data.isna().sum()\n",
    "for x in range(len(missing)):\n",
    "    print(str(data.columns[x]) + \": \" + str(missing[x]))\n",
    "    # print(missing[x])\n",
    "data.shape\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Large Data\n",
    "dataL = pd.read_csv(\"./Econ424_F2023_PC4_training_data_large.csv\")\n",
    "print(dataL.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat for large\n",
    "missingL = dataL.isna().sum()\n",
    "for x in range(len(missingL)):\n",
    "    print(str(dataL.columns[x]) + \": \" + str(missingL[x]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing is_certified, vehicicle_damage_category, combine_fuel_economy for all of them\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useless categories\n",
    "# fleet, is_cpo, is oemcpo major options, bed, bed height, bed length, cabin, iscab, transmission display, engine cylinders\n",
    "data.drop(['is_certified','vehicle_damage_category', 'combine_fuel_economy','wheel_system_display','fleet','is_cpo', 'is_oemcpo','bed',\n",
    "           'bed_height','bed_length','cabin','iscab',\n",
    "           'transmission_display','engine_cylinders'], errors='ignore',\n",
    "  axis='columns', inplace=True)\n",
    "dataL.drop(['is_certified','vehicle_damage_category', 'combine_fuel_economy','wheel_system_display','fleet','is_cpo', 'is_oemcpo','bed',\n",
    "            'bed_height','bed_length','cabin','iscab',\n",
    "            'transmission_display','engine_cylinders'], errors='ignore',\n",
    "  axis='columns', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove data points under 40000\n",
    "data = data[data['price'] >= 40000]\n",
    "dataL = dataL[dataL['price'] >= 40000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns\n",
    "data.shape\n",
    "\n",
    "dataL.columns\n",
    "dataL.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at data\n",
    "for col in data:\n",
    "    print(col)\n",
    "    print(data[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data to valid format\n",
    "\n",
    "floatCols = [\"back_legroom\", \"front_legroom\", \"height\", \"length\", \"wheelbase\", \"width\", \"fuel_tank_volume\"]\n",
    "intCols = [\"maximum_seating\"]\n",
    "for col in floatCols:\n",
    "    # Preprocess columns in small set\n",
    "    data[col] = data[col].str.split(' ').str[0]\n",
    "    data[col].replace('--', np.nan , inplace=True)\n",
    "    data[col] = pd.to_numeric(data[col],downcast='float')\n",
    "    \n",
    "    # Preprocess columns in large set\n",
    "    dataL[col] = dataL[col].str.split(' ').str[0]\n",
    "    dataL[col].replace('--', np.nan , inplace=True)\n",
    "    dataL[col] = pd.to_numeric(dataL[col],downcast='float')\n",
    "\n",
    "for col in intCols:\n",
    "    data[col] = data[col].str.split(' ').str[0]\n",
    "    data[col].replace('--', np.nan , inplace=True)\n",
    "    data[col] = pd.to_numeric(data[col],downcast='integer')\n",
    "    data[col].replace(np.nan, 5, inplace=True)\n",
    "    \n",
    "    dataL[col] = dataL[col].str.split(' ').str[0]\n",
    "    dataL[col].replace('--', np.nan , inplace=True)\n",
    "    dataL[col] = pd.to_numeric(dataL[col],downcast='integer')\n",
    "    dataL[col].replace(np.nan, 5, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in data.columns:\n",
    "    print(col + \": \" + str(data[col].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all with mean and mode\n",
    "categorical_columns = ['trimid','body_type','city','dealer_zip','engine_type','exterior_color','franchise_make','fuel_type','horsepower','interior_color'\n",
    "                       ,'listing_color','major_options','make_name','model_name','power','sp_name','torque','transmission','trim_name','wheel_system']\n",
    "bool_columns = ['frame_damaged','franchise_dealer','has_accidents','is_new','salvage','theft_title']\n",
    "\n",
    "for col in data.columns:\n",
    "    if col in categorical_columns or col in bool_columns:\n",
    "        # Replace \"--\" with NaN\n",
    "        data[col] = data[col].replace(np.nan, \"--\")\n",
    "        data[col] = data[col].replace(\"--\", pd.NA)\n",
    "        # Calculate the mode of the valid string values\n",
    "        mode_value = data[col].mode(dropna=True).iloc[0]\n",
    "\n",
    "        # Replace NaN with the mode\n",
    "        data[col].fillna(mode_value,inplace=True)\n",
    "        \n",
    "    elif col != \"listed_date\":\n",
    "        # calculate mean\n",
    "        # Convert non-numeric values (\"--\") to NaN\n",
    "        data[col] = pd.to_numeric(data[col], errors=\"coerce\")\n",
    "\n",
    "        # Calculate the mean of the valid numeric values\n",
    "        mean_value = data[col].dropna().mean()\n",
    "\n",
    "        # Replace NaN and \"--\" with the mean\n",
    "        data[col].fillna(mean_value, inplace=True)\n",
    "    \n",
    "        \n",
    "# Mean: back_legroom, city_fuel_economy, engine_displacement, front_legroom, fuel_tank_volume, height,\n",
    "# highway_fuel_economy,  mileage, wheelbase, width\n",
    "\n",
    "# Mode: maximum seating, owner count, seller rating, trimid\n",
    "\n",
    "# Repeat for large dataset\n",
    "for col in dataL.columns:\n",
    "    if col in categorical_columns or col in bool_columns:\n",
    "        # Replace \"--\" with NaN\n",
    "        dataL[col] = dataL[col].replace(np.nan, \"--\")\n",
    "        dataL[col] = dataL[col].replace(\"--\", pd.NA)\n",
    "        # Calculate the mode of the valid string values\n",
    "        mode_value = dataL[col].mode(dropna=True).iloc[0]\n",
    "\n",
    "        # Replace NaN with the mode\n",
    "        dataL[col].fillna(mode_value,inplace=True)\n",
    "        \n",
    "    elif col != \"listed_date\":\n",
    "        # calculate mean\n",
    "        # Convert non-numeric values (\"--\") to NaN\n",
    "        dataL[col] = pd.to_numeric(dataL[col], errors=\"coerce\")\n",
    "\n",
    "        # Calculate the mean of the valid numeric values\n",
    "        mean_value = dataL[col].dropna().mean()\n",
    "\n",
    "        # Replace NaN and \"--\" with the mean\n",
    "        dataL[col].fillna(mean_value, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in data.columns:\n",
    "    print(col + \": \" + str(data[col].unique()))\n",
    "    \n",
    "for col in dataL.columns:\n",
    "    print(col + \": \" + str(dataL[col].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm that data is now valid\n",
    "missing = data.isna().sum()\n",
    "for x in range(len(missing)):\n",
    "    print(str(data.columns[x]) + \": \" + str(missing[x]))\n",
    "    # print(missing[x])\n",
    "data.shape\n",
    "data.info()\n",
    "print(data['listed_date'])\n",
    "print(data['year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the csv files to not have to preprocess data each time\n",
    "# Updated csv file\n",
    "csv_file = \"./updatedSmall.csv\"\n",
    "\n",
    "\n",
    "# Use numpy.savetxt to save the array as a CSV file\n",
    "data.to_csv(csv_file,index=False, encoding=\"utf-8\", float_format=\"%1.6f\")\n",
    "\n",
    "# Updated csv file\n",
    "csv_fileL = \"./updatedLarge.csv\"\n",
    "\n",
    "\n",
    "# Use numpy.savetxt to save the array as a CSV file\n",
    "dataL.to_csv(csv_fileL,index=False, encoding=\"utf-8\", float_format=\"%1.6f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Label Encoder and Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./updatedSmall.csv\")\n",
    "dataL = pd.read_csv(\"./updatedLarge.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup categorical variables\n",
    "# label encoder to encode the different categorical features\n",
    "categorical_columns = ['trimid','body_type','city','dealer_zip','engine_type','exterior_color','franchise_make','fuel_type','horsepower','interior_color'\n",
    "                       ,'listing_color','major_options','make_name','model_name','power','sp_name','torque','transmission','trim_name','wheel_system']\n",
    "bool_columns = ['frame_damaged','franchise_dealer','has_accidents','is_new','salvage','theft_title']\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "for category in categorical_columns:\n",
    "    print(\"Doing it for category: \" + category)\n",
    "\n",
    "    data[category] = data[category].astype(str)\n",
    "    print(all)\n",
    "\n",
    "    data[category] = label_encoder.fit_transform(data[category])\n",
    "    \n",
    "    # Do same for large data set\n",
    "    dataL[category] = dataL[category].astype(str)\n",
    "    print(all)\n",
    "\n",
    "    dataL[category] = label_encoder.fit_transform(dataL[category])\n",
    "    \n",
    "\n",
    "for category in bool_columns:\n",
    "    print(\"Doing it for category: \" + category)\n",
    "\n",
    "    data[category] = data[category].astype(str)\n",
    "    print(all)\n",
    "\n",
    "    data[category] = label_encoder.fit_transform(data[category])\n",
    "\n",
    "    # Do same for large dataset\n",
    "    dataL[category] = dataL[category].astype(str)\n",
    "    print(all)\n",
    "\n",
    "    dataL[category] = label_encoder.fit_transform(dataL[category])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataL.head()\n",
    "dataL.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = data.isna().sum()\n",
    "\n",
    "for x in range(len(missing)):\n",
    "    print(str(data.columns[x]) + \": \" + str(missing[x]))\n",
    "    # print(missing[x])\n",
    "    \n",
    "missingL = dataL.isna().sum()\n",
    "\n",
    "for x in range(len(missing)):\n",
    "    print(str(dataL.columns[x]) + \": \" + str(missing[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['target'] = np.log(data['price'])\n",
    "dataL['target'] = np.log(dataL['price'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Different Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from matplotlib.pyplot import subplots\n",
    "from statsmodels.datasets import get_rdataset \n",
    "import sklearn.model_selection as skm\n",
    "from ISLP import load_data , confusion_table \n",
    "from ISLP.models import ModelSpec as MS\n",
    "from sklearn.tree import (DecisionTreeClassifier as DTC, DecisionTreeRegressor as DTR,  plot_tree, export_text)\n",
    "from sklearn.metrics import (accuracy_score , log_loss) \n",
    "from sklearn.ensemble import (RandomForestRegressor as RF, GradientBoostingRegressor as GBR)\n",
    "\n",
    "from matplotlib.pyplot import subplots \n",
    "import statsmodels.api as sm\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from matplotlib.pyplot import subplots\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Data\n",
    "Y = data['target']\n",
    "X = data.drop(columns=['price','target','listed_date'])\n",
    "\n",
    "YL = dataL['target']\n",
    "XL = dataL.drop(columns=['price','target','listed_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "X_trainL, X_testL, y_trainL, y_testL = train_test_split(XL, YL, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag = RF(max_features=X_train.shape[1],random_state=0)\n",
    "bag.fit(X_train,y_train)\n",
    "\n",
    "bagL = RF(max_features=X_trainL.shape[1],random_state=0)\n",
    "bagL.fit(X_trainL,y_trainL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = subplots(figsize=(8,8))[1] \n",
    "y_hat_bag = bag.predict(X_test) \n",
    "ax.scatter(y_hat_bag, y_test) \n",
    "\n",
    "# calculate mse\n",
    "mse = mean_squared_error(y_test, y_hat_bag)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "\n",
    "r2 = r2_score(y_test, y_hat_bag)\n",
    "print(f'R^2: {r2}')\n",
    "\n",
    "\n",
    "\n",
    "# Repeat for Large\n",
    "axL = subplots(figsize=(8,8))[1] \n",
    "y_hat_bagL = bagL.predict(X_testL) \n",
    "axL.scatter(y_hat_bagL, y_testL) \n",
    "\n",
    "# calculate mse\n",
    "mse = mean_squared_error(y_testL, y_hat_bagL)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "\n",
    "r2 = r2_score(y_testL, y_hat_bagL)\n",
    "print(f'R^2: {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp = pd.DataFrame( {'importance':bag.feature_importances_}, index=X.columns)\n",
    "feature_imp.sort_values(by='importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_impL = pd.DataFrame( {'importance':bagL.feature_importances_}, index=XL.columns)\n",
    "feature_impL.sort_values(by='importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bag = RF(max_features=X_train.shape[1], n_estimators=500, random_state=0).fit(X_train, y_train) \n",
    "y_hat_bag_500 = data_bag.predict(X_test)\n",
    "\n",
    "\n",
    "data_bagL = RF(max_features=X_trainL.shape[1], n_estimators=500, random_state=0).fit(X_trainL, y_trainL) \n",
    "y_hat_bag_500L = data_bagL.predict(X_testL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test, y_hat_bag_500)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "\n",
    "r2 = r2_score(y_test, y_hat_bag_500)\n",
    "print(f'R^2: {r2}')\n",
    "\n",
    "mse = mean_squared_error(y_testL, y_hat_bag_500L)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "\n",
    "r2 = r2_score(y_testL, y_hat_bag_500L)\n",
    "print(f'R^2: {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = subplots(figsize=(8,8))[1] \n",
    "ax.scatter(y_hat_bag_500, y_test) \n",
    "ax.title.set_text('Log Car Price (Predicted vs Actual) in Small Dataset with Bagging')\n",
    "ax.set_xlabel(\"Log Observed Car Prices\")\n",
    "ax.set_ylabel(\"Log Predicted Car Prices\")\n",
    "ax.axline((10.5,10.5), slope=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = subplots(figsize=(8,8))[1] \n",
    "ax.scatter(y_hat_bag_500L, y_testL) \n",
    "ax.title.set_text('Log Car Price (Predicted vs Actual) in Large Dataset with Bagging')\n",
    "ax.set_xlabel(\"Log Observed Car Prices\")\n",
    "ax.set_ylabel(\"Log Predicted Car Prices\")\n",
    "ax.axline((10.5,10.5), slope=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp = pd.DataFrame( {'importance':data_bag.feature_importances_}, index=X.columns)\n",
    "feature_imp.sort_values(by='importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp = pd.DataFrame( {'importance':data_bagL.feature_importances_}, index=XL.columns)\n",
    "feature_imp.sort_values(by='importance', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RF(max_features=int(np.sqrt(X_train.shape[1])),random_state=0)\n",
    "rf.fit(X_train,y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfL = RF(max_features=int(np.sqrt(X_trainL.shape[1])),random_state=0)\n",
    "rfL.fit(X_trainL,y_trainL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = subplots(figsize=(8,8))[1] \n",
    "y_hat_rf = rf.predict(X_test) \n",
    "ax.scatter(y_hat_rf, y_test) \n",
    "np.mean((y_test - y_hat_rf)**2)\n",
    "ax.title.set_text('Log Car Price (Predicted vs Actual) in Small Dataset with Random Forest')\n",
    "ax.set_xlabel(\"Log Observed Car Prices\")\n",
    "ax.set_ylabel(\"Log Predicted Car Prices\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = subplots(figsize=(8,8))[1] \n",
    "y_hat_rfL = rfL.predict(X_testL) \n",
    "ax.scatter(y_hat_rfL, y_testL) \n",
    "np.mean((y_testL - y_hat_rfL)**2)\n",
    "ax.title.set_text('Log Car Price (Predicted vs Actual) in Large Dataset with Random Forest')\n",
    "ax.set_xlabel(\"Log Observed Car Prices\")\n",
    "ax.set_ylabel(\"Log Predicted Car Prices\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test, y_hat_rf)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "\n",
    "r2 = r2_score(y_test, y_hat_rf)\n",
    "print(f'R^2: {r2}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mse = mean_squared_error(y_testL, y_hat_rfL)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "\n",
    "r2 = r2_score(y_testL, y_hat_rfL)\n",
    "print(f'R^2: {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp = pd.DataFrame( {'importance':rf.feature_importances_}, index=X.columns)\n",
    "feature_imp.sort_values(by='importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp = pd.DataFrame( {'importance':rfL.feature_importances_}, index=XL.columns)\n",
    "feature_imp.sort_values(by='importance', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_boost = GBR(n_estimators=5000, learning_rate=0.2, max_depth=3, random_state=0)\n",
    "data_boost.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_boostL = GBR(n_estimators=5000, learning_rate=0.2, max_depth=3, random_state=0)\n",
    "data_boostL.fit(X_trainL, y_trainL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_error = np.zeros_like(data_boost.train_score_)\n",
    "for idx, y_ in enumerate(data_boost.staged_predict(X_test)):\n",
    "    test_error[idx] = np.mean((y_test - y_)**2)\n",
    "plot_idx = np.arange(data_boost.train_score_.shape[0]) \n",
    "ax = subplots(figsize=(8,8))[1]\n",
    "ax.plot(plot_idx,data_boost.train_score_, 'b',label='Training')\n",
    "ax.plot(plot_idx, test_error ,'r',label='Test') \n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_errorL = np.zeros_like(data_boostL.train_score_)\n",
    "for idx, y_ in enumerate(data_boostL.staged_predict(X_testL)):\n",
    "    test_error[idx] = np.mean((y_testL - y_)**2)\n",
    "plot_idx = np.arange(data_boostL.train_score_.shape[0]) \n",
    "ax = subplots(figsize=(8,8))[1]\n",
    "ax.plot(plot_idx,data_boostL.train_score_, 'b',label='Training')\n",
    "ax.plot(plot_idx, test_errorL ,'r',label='Test') \n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = subplots(figsize=(8,8))[1] \n",
    "y_hat_boost = data_boost.predict(X_test) \n",
    "ax.scatter(y_hat_boost, y_test) \n",
    "np.mean((y_test - y_hat_boost)**2)\n",
    "ax.title.set_text('Log Car Price (Predicted vs Actual) in Small Dataset with Boosting')\n",
    "ax.set_xlabel(\"Log Observed Car Prices\")\n",
    "ax.set_ylabel(\"Log Predicted Car Prices\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = subplots(figsize=(8,8))[1] \n",
    "y_hat_boostL = data_boostL.predict(X_testL) \n",
    "ax.scatter(y_hat_boostL, y_testL) \n",
    "ax.title.set_text('Log Car Price (Predicted vs Actual) in Large Dataset with Boosting')\n",
    "ax.set_xlabel(\"Log Observed Car Prices\")\n",
    "ax.set_ylabel(\"Log Predicted Car Prices\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test, y_hat_boost)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "\n",
    "r2 = r2_score(y_test, y_hat_boost)\n",
    "print(f'R^2: {r2}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mse = mean_squared_error(y_testL, y_hat_boostL)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "\n",
    "r2 = r2_score(y_testL, y_hat_boostL)\n",
    "print(f'R^2: {r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data to DMatrix format, which is used by XGBoost\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "params = {\n",
    "'objective': 'reg:squarederror',\n",
    "'eval_metric': 'rmse',\n",
    "'eta': 0.1, # lr\n",
    "'max_depth': 9, # depth\n",
    "'subsample': 0.3,\n",
    "'colsample_bytree': 0.3\n",
    "}\n",
    "# train\n",
    "num_round = 150\n",
    "model = xgb.train(params, dtrain, num_round)\n",
    "# predict\n",
    "y_train_xgb = model.predict(dtrain)\n",
    "y_hat_xgb = model.predict(dtest)\n",
    "\n",
    "\n",
    "# calculate mse\n",
    "mse = mean_squared_error(y_test, y_hat_xgb)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "\n",
    "r2 = r2_score(y_test, y_hat_xgb)\n",
    "print(f'R^2: {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Large model\n",
    "dtrainL = xgb.DMatrix(X_trainL, label=y_trainL)\n",
    "dtestL = xgb.DMatrix(X_testL, label=y_testL)\n",
    "modelL = xgb.train(params, dtrainL, num_round)\n",
    "# predict\n",
    "y_train_xgbL = modelL.predict(dtrainL)\n",
    "y_hat_xgbL = modelL.predict(dtestL)\n",
    "\n",
    "\n",
    "# calculate mse\n",
    "mse = mean_squared_error(y_testL, y_hat_xgbL)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "\n",
    "r2 = r2_score(y_testL, y_hat_xgbL)\n",
    "print(f'R^2: {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = subplots(figsize=(8,8))[1] \n",
    "ax.scatter(y_hat_xgb, y_test) \n",
    "np.mean((y_test - y_hat_xgb)**2)\n",
    "ax.title.set_text('Log Car Price (Predicted vs Actual) in Small Dataset with XGBoost')\n",
    "ax.set_xlabel(\"Log Observed Car Prices\")\n",
    "ax.set_ylabel(\"Log Predicted Car Prices\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = subplots(figsize=(8,8))[1] \n",
    "ax.scatter(y_hat_xgbL, y_testL) \n",
    "np.mean((y_testL - y_hat_xgbL)**2)\n",
    "ax.title.set_text('Log Car Price (Predicted vs Actual) in Large Dataset with XGBoost')\n",
    "ax.set_xlabel(\"Log Observed Car Prices\")\n",
    "ax.set_ylabel(\"Log Predicted Car Prices\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create log charts for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose best one\n",
    "bestModel = data_bag\n",
    "bestModelL = data_bagL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess prediction data\n",
    "# Read in Data\n",
    "dataPred = pd.read_csv(\"./Econ424_F2023_PC5_test_data_without_response_var.csv\")\n",
    "print(dataPred.head())\n",
    "\n",
    "dataPred.drop(['is_certified','vehicle_damage_category', 'combine_fuel_economy','wheel_system_display','fleet','is_cpo', 'is_oemcpo','bed','bed_height','bed_length','cabin','iscab','transmission_display','engine_cylinders','listed_date'], errors='ignore',\n",
    "  axis='columns', inplace=True)\n",
    "dataPred.shape\n",
    "\n",
    "weirdCols = [\"back_legroom\", \"front_legroom\", \"height\", \"length\", \"wheelbase\", \"width\", \"maximum_seating\", \"fuel_tank_volume\"]\n",
    "# Iterate through the columns and extract float components for matching columns\n",
    "for column in weirdCols:\n",
    "    if len(dataPred[column].unique()) >= 4 and dataPred[column].dtype == object:\n",
    "        print(column)\n",
    "        for i in range(len(dataPred[column])):\n",
    "                if pd.isna(dataPred[column][i]):\n",
    "                    continue\n",
    "                elif isinstance(dataPred[column][i], str):\n",
    "                    # print(\"found string\")\n",
    "                   \n",
    "                    if len(dataPred[column][i]) <= 2:\n",
    "                        continue\n",
    "                    end = dataPred[column][i][-3:]\n",
    "                    if end == \" in\":\n",
    "                        dataPred[column][i] = float(dataPred[column][i][:-3])\n",
    "                        continue\n",
    "                    if len(dataPred[column][i]) <= 3:\n",
    "                        continue\n",
    "                    end = dataPred[column][i][-4:]\n",
    "                    if end == \" gal\":\n",
    "                        dataPred[column][i] = float(dataPred[column][i][:-4])\n",
    "                        continue\n",
    "                    \n",
    "                    if len(dataPred[column][i]) <= 5:\n",
    "                        continue\n",
    "                    end = dataPred[column][i][-6:]\n",
    "                    if end == \" seats\":\n",
    "                        dataPred[column][i] = int(dataPred[column][i][:-6])\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all with mean and mode\n",
    "categorical_columns = ['trimid','body_type','city','dealer_zip','engine_type','exterior_color','franchise_make','fuel_type','horsepower','interior_color'\n",
    "                       ,'listing_color','major_options','make_name','model_name','power','sp_name','torque','transmission','trim_name','wheel_system']\n",
    "bool_columns = ['frame_damaged','franchise_dealer','has_accidents','is_new','salvage','theft_title']\n",
    "\n",
    "for col in dataPred.columns:\n",
    "    if col in categorical_columns or col in bool_columns:\n",
    "        # calculate mode\n",
    "        average = \"-1\"\n",
    "        # Replace \"--\" with NaN\n",
    "        dataPred[col] = dataPred[col].replace(np.nan, \"--\")\n",
    "        dataPred[col] = dataPred[col].replace(\"--\", pd.NA)\n",
    "        # Calculate the mode of the valid string values\n",
    "        mode_value = dataPred[col].mode(dropna=True).iloc[0]\n",
    "\n",
    "        # Replace NaN with the mode\n",
    "        dataPred[col].fillna(mode_value,inplace=True)\n",
    "        \n",
    "    elif col != \"listed_date\":\n",
    "        # calculate mean\n",
    "        # Convert non-numeric values (\"--\") to NaN\n",
    "        dataPred[col] = pd.to_numeric(dataPred[col], errors=\"coerce\")\n",
    "\n",
    "        # Calculate the mean of the valid numeric values\n",
    "        mean_value = dataPred[col].dropna().mean()\n",
    "\n",
    "        # Replace NaN and \"--\" with the mean\n",
    "        dataPred[col].fillna(mean_value, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['trimid','body_type','city','dealer_zip','engine_type','exterior_color','franchise_make','fuel_type','horsepower','interior_color'\n",
    "                       ,'listing_color','major_options','make_name','model_name','power','sp_name','torque','transmission','trim_name','wheel_system']\n",
    "bool_columns = ['frame_damaged','franchise_dealer','has_accidents','is_new','salvage','theft_title']\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "for category in categorical_columns:\n",
    "    print(\"Doing it for category: \" + category)\n",
    "    dataPred[category] = dataPred[category].astype(str)\n",
    "    print(all)\n",
    "\n",
    "    dataPred[category] = label_encoder.fit_transform(dataPred[category])\n",
    "for category in bool_columns:\n",
    "    print(\"Doing it for category: \" + category)\n",
    "    dataPred[category] = dataPred[category].astype(str)\n",
    "    print(all)\n",
    "\n",
    "    dataPred[category] = label_encoder.fit_transform(dataPred[category])\n",
    "\n",
    "missing = dataPred.isna().sum()\n",
    "\n",
    "for x in range(len(missing)):\n",
    "    print(str(dataPred.columns[x]) + \": \" + str(missing[x]))\n",
    "    # print(missing[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPred.drop(columns=['price'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply prediction\n",
    "Y_test = bestModel.predict(dataPred)\n",
    "Y_testL = bestModelL.predict(dataPred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(Y_test))\n",
    "print(len(Y_testL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output to csv file\n",
    "csv_file_out = \"./output.csv\"\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "np.savetxt(csv_file_out, Y_test, delimiter=\"\\n\", fmt=\"%1.6f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output to csv file\n",
    "csv_file_outL = \"./outputL.csv\"\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "np.savetxt(csv_file_outL, Y_testL, delimiter=\"\\n\", fmt=\"%1.6f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot of Sales Price vs Mileage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "# Create a new DataFrame with average prices for each mileage bin\n",
    "max_mileage = 200000\n",
    "mileage_bins = range(1000, max_mileage, 500)\n",
    "\n",
    "# Calculate bins and average prices\n",
    "df['mileage_bins'] = pd.cut(df['mileage'], bins=mileage_bins, right=False)\n",
    "avg_prices = df.groupby('mileage_bins')['price'].mean().reset_index()    \n",
    "    \n",
    "# Set the size of the plot\n",
    "plt.figure(figsize=(20, 20))  # Adjust the width and height as needed\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,12))\n",
    "\n",
    "# Plot the average prices for each mileage bin\n",
    "ax.scatter(mileage_bins[:-1], avg_prices['price'])\n",
    "\n",
    "# Set the y-axis ticks to go up by 2000\n",
    "ax.set_xticks(np.arange(0, max_mileage+10000, 10000))\n",
    "ax.set_yticks(np.arange(6000, max(avg_prices['price']) + 2000, 2000))\n",
    "\n",
    "# Label the axes\n",
    "ax.set_xlabel('Mileage (rounded to nearest 500)')\n",
    "ax.set_ylabel('Average Car Sales Price')\n",
    "ax.set_title('Sale Price vs Mileage')\n",
    "ax.set_xlim(0,max_mileage)\n",
    "\n",
    "# # Add vertical lines at each 10,000-mile mark\n",
    "for mile_mark in range(10000, max_mileage, 10000):\n",
    "    ax.axvline(x=mile_mark, color='gray', linestyle='--', linewidth=1)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "econ424",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
